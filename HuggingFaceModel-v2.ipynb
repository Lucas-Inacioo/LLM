{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddd23879-75a5-42a4-adc1-3d1a712b2f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "from langchain import PromptTemplate\n",
    "from langchain import HuggingFaceHub, LLMChain\n",
    "\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8eb929fc-6657-453b-97a7-cbf66546ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminho para o arquivo JSON\n",
    "file_path = './datasets/Classification/email.json'\n",
    "\n",
    "# Carregar o arquivo JSON\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    questoes = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52961811-ee7e-4e60-90e7-892dce2e85e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suprimir warning que não vai ser importante para nosso contexto atual\n",
    "warnings.filterwarnings(\"ignore\", message=\".*The function `run` was deprecated in LangChain 0.1.0.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b4553d-8c85-4dcf-a250-9fbce0be9ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template para o prompt\n",
    "template = \"\"\"Classify the following question as one of these categories Português, Literatura, Redação, Biologia, Geografia, Matemática, Física, História, Química, Inglês, Espanhol, Filosofia, Sociologia, História da Arte, Orientação de Estudos e Ensino Religioso: {question}\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=['question']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca611257-fca3-46b8-93d0-e3b72a26626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seguindo o modelo: https://www.pinecone.io/learn/series/langchain/langchain-intro/\n",
    "# initialize Hub LLM\n",
    "hub_llm = HuggingFaceHub(\n",
    "        repo_id='google/flan-t5-large',\n",
    "        model_kwargs={'temperature':1e-10}\n",
    "    )\n",
    "\n",
    "# create prompt template > LLM chain\n",
    "llm_chain = LLMChain(\n",
    "    prompt=prompt,\n",
    "    llm=hub_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "930edd20-018f-45bf-969d-8b17cc9f4c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coletar áreas esperadas do Json\n",
    "perguntas = [questao['question'] for questao in questoes]\n",
    "\n",
    "tempos_de_execucao = []\n",
    "areas_previstas = []\n",
    "# Coletar previsões do modelo e tempos de chamada\n",
    "for pergunta in perguntas:\n",
    "    start_time = time.time()\n",
    "    areas_previstas.append(llm_chain.run(pergunta))\n",
    "    end_time = time.time()\n",
    "    tempos_de_execucao.append(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7adac713-adff-4fcc-a09f-587f14c51247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Pergunta  |       Previsto       |         Real         |  Tempo(s) \n",
      "--------------------------------------------------------------------------------\n",
      "    1      |       Biologia       |       Química        |    0.16   \n",
      "    2      |       Biologia       |       Biologia       |    0.16   \n",
      "    3      |      Matemática      |      Matemática      |    0.16   \n",
      "    4      |      Matemática      |      Matemática      |    0.16   \n",
      "    5      |       Biologia       |       Biologia       |    0.16   \n",
      "    6      |   História da Arte   |       História       |    0.16   \n",
      "    7      |      Sociologia      |      Literatura      |    0.16   \n",
      "    8      |      Matemática      |      Matemática      |    0.16   \n",
      "    9      |      Matemática      |      Matemática      |    0.16   \n",
      "    10     |      Matemática      |        Física        |    0.16   \n",
      "\n",
      "Precisão do modelo: 60.00%\n"
     ]
    }
   ],
   "source": [
    "# Cálculo da precisão do modelo\n",
    "areas_corretas = [questao['area'] for questao in questoes]\n",
    "acertos = sum(1 for area_prevista, area_correta in zip(areas_previstas, areas_corretas) if area_prevista == area_correta)\n",
    "total_perguntas = len(questoes)\n",
    "precisao = acertos / total_perguntas\n",
    "\n",
    "# Fazendo um print comparativo de cada tentativa/real e a precisão do modelo\n",
    "print(f'{\"Pergunta\":^10} | {\"Previsto\":^20} | {\"Real\":^20} | {\"Tempo(s)\":^10}')\n",
    "print('-'*80)\n",
    "for i, ((previsto, real), tempo) in enumerate(zip(zip(areas_previstas, areas_corretas), tempos_de_execucao), 1):\n",
    "    print(f'{i:^10} | {previsto:^20} | {real:^20} | {tempo:^10.2f}')\n",
    "\n",
    "print(f'\\nPrecisão do modelo: {precisao:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e277f899-3a98-4fa4-8ad7-be61e88d555b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
